# Kani TTS Docker Compose
#
# Two options:
#   1. Use pre-built HuggingFace image (faster startup, Gradio UI on :7860)
#   2. Build our custom API image (REST API on :7861)
#
# For integration with the audiobook generator, we run both:
#   - HF image for the actual TTS processing (proven to work)
#   - Our lightweight proxy that calls the Gradio API

version: "3.8"

services:
  # Option A: HuggingFace Space image (official, includes Gradio UI)
  kani-hf:
    image: registry.hf.space/nineninesix-kani-tts-2-pt:latest
    platform: linux/amd64
    ports:
      - "7860:7860"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
    restart: unless-stopped
    profiles:
      - hf
      - all

  # Option B: Our custom API server (cleaner REST interface)
  kani-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "7861:7860"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - PORT=7860
      - SPEAKER_MAP=/app/speakers/speaker_map.json
    volumes:
      # Mount cloned voices directory for persistence
      - ./cloned_voices:/app/cloned_voices
    restart: unless-stopped
    profiles:
      - api
      - all

  # Gradio API proxy (lightweight, uses HF space via Gradio client)
  kani-proxy:
    build:
      context: .
      dockerfile: Dockerfile.proxy
    ports:
      - "7862:7862"
    environment:
      - GRADIO_URL=http://kani-hf:7860
      - PORT=7862
    depends_on:
      - kani-hf
    restart: unless-stopped
    profiles:
      - proxy
